"""–°—Ö–µ–º–∞ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ LLM –∞–Ω–∞–ª–∏–∑–∞"""
import psycopg2


def recreate_llm_news_table(conn: psycopg2.extensions.connection):
    """–ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å —É–¥–∞–ª–µ–Ω–∏–µ–º —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    cursor = conn.cursor()
    
    try:
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é —Ç–∞–±–ª–∏—Ü—É
        cursor.execute("DROP TABLE IF EXISTS llm_analyzed_news CASCADE;")
        print("üóëÔ∏è  –°—Ç–∞—Ä–∞—è —Ç–∞–±–ª–∏—Ü–∞ llm_analyzed_news —É–¥–∞–ª–µ–Ω–∞")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
        create_table_sql = """
        CREATE TABLE llm_analyzed_news (
            id SERIAL PRIMARY KEY,
            id_old INTEGER NOT NULL,
            id_cluster INTEGER NOT NULL,
            headline TEXT NOT NULL,
            content TEXT,
            headline_en TEXT,
            content_en TEXT,
            urls_json TEXT,
            published_time TIMESTAMP,
            ai_hotness REAL,
            tickers_json TEXT,
            reasoning TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(id_cluster),
            FOREIGN KEY (id_old) REFERENCES normalized_articles(id) ON DELETE CASCADE,
            FOREIGN KEY (id_cluster) REFERENCES story_clusters(id) ON DELETE CASCADE
        );
        """
        cursor.execute(create_table_sql)
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        indexes = [
            "CREATE INDEX idx_llm_news_cluster ON llm_analyzed_news(id_cluster);",
            "CREATE INDEX idx_llm_news_hotness ON llm_analyzed_news(ai_hotness DESC);",
            "CREATE INDEX idx_llm_news_published ON llm_analyzed_news(published_time DESC);"
        ]
        
        for index_sql in indexes:
            cursor.execute(index_sql)
        
        conn.commit()
        print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ llm_analyzed_news –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ —Å –Ω–æ–≤–æ–π —Å—Ö–µ–º–æ–π")
        
    except psycopg2.Error as e:
        conn.rollback()
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã: {e}")
        raise


def create_llm_news_table(conn: psycopg2.extensions.connection):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ LLM –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    create_table_sql = """
    CREATE TABLE IF NOT EXISTS llm_analyzed_news (
        id SERIAL PRIMARY KEY,
        id_old INTEGER NOT NULL,  -- ID –∏–∑ normalized_articles
        id_cluster INTEGER NOT NULL,  -- ID –∏–∑ story_clusters
        headline TEXT NOT NULL,
        content TEXT,
        headline_en TEXT,  -- –ê–Ω–≥–ª–∏–π—Å–∫–∞—è –≤–µ—Ä—Å–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
        content_en TEXT,  -- –ê–Ω–≥–ª–∏–π—Å–∫–∞—è –≤–µ—Ä—Å–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
        urls_json TEXT,  -- JSON –º–∞—Å—Å–∏–≤ —Å—Å—ã–ª–æ–∫
        published_time TIMESTAMP,
        ai_hotness REAL,  -- –û—Ü–µ–Ω–∫–∞ –≥–æ—Ä—è—á–Ω–æ—Å—Ç–∏ –æ—Ç LLM (0-1)
        tickers_json TEXT,  -- JSON –º–∞—Å—Å–∏–≤ —Ç–∏–∫–µ—Ä–æ–≤
        reasoning TEXT,  -- –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ (—Ñ–æ—Ä–º—É–ª–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤)
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(id_cluster),  -- –û–¥–∏–Ω –∫–ª–∞—Å—Ç–µ—Ä –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ä–∞–∑
        FOREIGN KEY (id_old) REFERENCES normalized_articles(id) ON DELETE CASCADE,
        FOREIGN KEY (id_cluster) REFERENCES story_clusters(id) ON DELETE CASCADE
    );
    """
    
    cursor = conn.cursor()
    cursor.execute(create_table_sql)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –≤–µ—Ä—Å–∏–π, –µ—Å–ª–∏ –∏—Ö –µ—â–µ –Ω–µ—Ç (–º–∏–≥—Ä–∞—Ü–∏—è –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü)
    try:
        cursor.execute("""
            ALTER TABLE llm_analyzed_news 
            ADD COLUMN IF NOT EXISTS headline_en TEXT;
        """)
        cursor.execute("""
            ALTER TABLE llm_analyzed_news 
            ADD COLUMN IF NOT EXISTS content_en TEXT;
        """)
        # –ï—Å–ª–∏ headline_en –ø—É—Å—Ç–æ–π, –∑–∞–ø–æ–ª–Ω—è–µ–º –µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –∏–∑ headline (–¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π)
        cursor.execute("""
            UPDATE llm_analyzed_news 
            SET headline_en = headline 
            WHERE headline_en IS NULL OR headline_en = '';
        """)
        cursor.execute("""
            UPDATE llm_analyzed_news 
            SET content_en = content 
            WHERE content_en IS NULL AND content IS NOT NULL;
        """)
        conn.commit()
        print("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è: –¥–æ–±–∞–≤–ª–µ–Ω—ã –ø–æ–ª—è headline_en –∏ content_en")
    except psycopg2.Error as e:
        conn.rollback()
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ (–≤–æ–∑–º–æ–∂–Ω–æ, –ø–æ–ª—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç): {e}")
    
    # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    indexes = [
        "CREATE INDEX IF NOT EXISTS idx_llm_news_cluster ON llm_analyzed_news(id_cluster);",
        "CREATE INDEX IF NOT EXISTS idx_llm_news_hotness ON llm_analyzed_news(ai_hotness DESC);",
        "CREATE INDEX IF NOT EXISTS idx_llm_news_published ON llm_analyzed_news(published_time DESC);"
    ]
    
    for index_sql in indexes:
        cursor.execute(index_sql)
    
    conn.commit()
    print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ llm_analyzed_news —Å–æ–∑–¥–∞–Ω–∞")


def get_unprocessed_clusters(conn: psycopg2.extensions.connection, limit: int = None):
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã"""
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º NOT EXISTS –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    query = """
    SELECT 
        sc.id as cluster_id,
        sc.headline,
        sc.first_time,
        sc.doc_count,
        sc.urls_json,
        sc.hotness as original_hotness
    FROM story_clusters sc
    WHERE NOT EXISTS (
        SELECT 1 FROM llm_analyzed_news lan 
        WHERE lan.id_cluster = sc.id
    )
    ORDER BY sc.first_time DESC
    """
    
    if limit:
        query += f" LIMIT {limit}"
    
    cursor = conn.cursor()
    cursor.execute(query)
    
    columns = [desc[0] for desc in cursor.description]
    results = []
    for row in cursor.fetchall():
        results.append(dict(zip(columns, row)))
    
    return results


def get_cluster_representative_article(conn: psycopg2.extensions.connection, cluster_id: int):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å–Ω—É—é —Å—Ç–∞—Ç—å—é –∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞"""
    
    query = """
    SELECT 
        na.id as normalized_id,
        na.title,
        na.content,
        na.published_at,
        cm.url
    FROM cluster_members cm
    JOIN normalized_articles na ON cm.normalized_id = na.id
    WHERE cm.cluster_id = %s
    ORDER BY cm.time_utc ASC  -- –ë–µ—Ä–µ–º —Å–∞–º—É—é —Ä–∞–Ω–Ω—é—é
    LIMIT 1
    """
    
    cursor = conn.cursor()
    try:
        cursor.execute(query, (cluster_id,))
        
        row = cursor.fetchone()
        if not row:
            return None
        
        columns = [desc[0] for desc in cursor.description]
        return dict(zip(columns, row))
    except psycopg2.Error as e:
        conn.rollback()
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞ {cluster_id}: {e}")
        return None


def insert_llm_analyzed_news(conn: psycopg2.extensions.connection, data: dict):
    """–í—Å—Ç–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç LLM –∞–Ω–∞–ª–∏–∑–∞"""
    
    insert_sql = """
    INSERT INTO llm_analyzed_news 
        (id_old, id_cluster, headline, content, headline_en, content_en, urls_json, published_time, 
         ai_hotness, tickers_json, reasoning)
    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    ON CONFLICT (id_cluster) DO NOTHING
    RETURNING id
    """
    
    cursor = conn.cursor()
    try:
        cursor.execute(insert_sql, (
            data['id_old'],
            data['id_cluster'],
            data['headline'],
            data.get('content'),
            data.get('headline_en') or data['headline'],  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω–≥–ª–∏–π—Å–∫—É—é –≤–µ—Ä—Å–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ—Ä–∏–≥–∏–Ω–∞–ª
            data.get('content_en') or data.get('content') or data['headline'],
            data['urls_json'],
            data['published_time'],
            data['ai_hotness'],
            data['tickers_json'],
            data.get('reasoning', '')
        ))
        
        result = cursor.fetchone()
        conn.commit()
        
        return result[0] if result else None
        
    except psycopg2.Error as e:
        conn.rollback()
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞ {data['id_cluster']}: {e}")
        return None

