"""News analyzer for generating detailed information via LLM"""
import json
import os
from typing import Dict
from ..llm.proxyapi_client import ProxyAPIClient


class NewsAnalyzer:
    """Generates detailed analytics for news"""
    
    def __init__(self, api_key: str = None, model: str = None):
        # Use more powerful model for detailed analysis
        # LLM_ANALYSIS_MODEL - for detailed analysis (default Claude 3.5 Sonnet)
        # LLM_MODEL - for quick hotness evaluation
        self.analysis_model = model or os.getenv("LLM_ANALYSIS_MODEL", "anthropic/claude-3.5-sonnet")
        self.llm_client = ProxyAPIClient(api_key=api_key, model=self.analysis_model)
    
    def generate_full_analysis(self, news: Dict) -> Dict:
        """
        Generates full news analysis in analytical card format
        
        Args:
            news: dict with headline, content, tickers, hotness, urls, published_at, source
            
        Returns:
            {
                'analysis_text': str - ready card in Markdown format
            }
        """
        
        print("\n" + "="*60)
        print("ğŸ” ĞĞĞ§ĞĞ›Ğ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜ Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞĞ“Ğ ĞĞĞĞ›Ğ˜Ğ—Ğ")
        print("="*60)
        
        headline = news.get('headline', '')
        content = news.get('content', '')
        tickers = news.get('tickers', [])
        hotness = news.get('hotness', 0)
        urls = news.get('urls', [])
        published_at = news.get('published_at', '')
        source = news.get('source', 'Unknown source')
        
        print(f"ğŸ“° ĞĞ¾Ğ²Ğ¾ÑÑ‚ÑŒ: {headline[:50]}...")
        print(f"ğŸ”¢ Hotness: {hotness}")
        print(f"ğŸ“ URL: {urls[0] if urls else 'Ğ½ĞµÑ‚'}")
        
        # Create prompt for analytical card generation
        prompt = self._create_analysis_card_prompt(headline, content, tickers, hotness, urls, published_at, source)
        
        headers = {
            "Authorization": f"Bearer {self.llm_client.api_key}",
            "Content-Type": "application/json"
        }
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ payload Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° API
        api_format = self.llm_client.api_format
        print(f"ğŸ”§ Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ API: {api_format}")
        print(f"ğŸŒ Base URL: {self.llm_client.base_url}")
        print(f"ğŸ¤– Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {self.analysis_model}")
        print(f"ğŸ¯ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {self.llm_client.model}")
        
        if api_format == "anthropic":
            payload = {
                "model": self.llm_client.model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 1500,
                "temperature": 0.3
            }
        else:
            payload = {
                "model": self.llm_client.model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.3,
                "max_tokens": 1500
            }
        
        print(f"ğŸ“¦ Payload keys: {list(payload.keys())}")
        print(f"ğŸ“ Prompt length: {len(prompt)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
        
        # Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸
        print(f"\nğŸ” Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞĞ¯ Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ Ğ Ğ—ĞĞŸĞ ĞĞ¡Ğ•:")
        print(f"   ğŸ“ URL: {self.llm_client.base_url}")
        print(f"   ğŸ”‘ API Key (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 10 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²): {headers.get('Authorization', 'N/A')[:20]}...")
        print(f"   ğŸ¤– ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ² payload: {payload.get('model', 'N/A')}")
        print(f"   ğŸ“Š Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ API: {api_format}")
        print(f"   ğŸ“ Max tokens: {payload.get('max_tokens', 'N/A')}")
        print(f"   ğŸŒ¡ï¸ Temperature: {payload.get('temperature', 'N/A')}")
        print(f"   ğŸ’¬ ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹: {len(payload.get('messages', []))}")
        
        try:
            import requests
            print(f"\nğŸš€ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğº API...")
            print(f"   Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ ProxyAPI:")
            print(f"   - URL Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ: https://api.proxyapi.ru/anthropic/v1/messages")
            print(f"   - ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Ñ Ğ´ĞµÑ„Ğ¸ÑĞ°Ğ¼Ğ¸: claude-3-5-sonnet")
            print(f"   - Authorization: Bearer <ĞšĞ›Ğ®Ğ§>")
            
            try:
                response = requests.post(
                    self.llm_client.base_url,
                    headers=headers,
                    json=payload,
                    timeout=30
                )
            except requests.exceptions.Timeout:
                print(f"\nâŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: ĞŸÑ€ĞµĞ²Ñ‹ÑˆĞµĞ½Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¾Ñ‚ API (30 ÑĞµĞºÑƒĞ½Ğ´)")
                print(f"   URL: {self.llm_client.base_url}")
                return self._get_fallback_analysis(
                    news.get('hotness', 0),
                    news.get('urls', []),
                    news.get('published_at', ''),
                    news.get('source', 'Unknown source')
                )
            except requests.exceptions.ConnectionError as e:
                print(f"\nâŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº API")
                print(f"   Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸: {e}")
                print(f"   URL: {self.llm_client.base_url}")
                return self._get_fallback_analysis(
                    news.get('hotness', 0),
                    news.get('urls', []),
                    news.get('published_at', ''),
                    news.get('source', 'Unknown source')
                )
            except requests.exceptions.RequestException as e:
                print(f"\nâŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ Ğº API")
                print(f"   Ğ¢Ğ¸Ğ¿ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸: {type(e).__name__}")
                print(f"   Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸: {e}")
                return self._get_fallback_analysis(
                    news.get('hotness', 0),
                    news.get('urls', []),
                    news.get('published_at', ''),
                    news.get('source', 'Unknown source')
                )
            
            print(f"\nğŸ“¡ ĞĞ¢Ğ’Ğ•Ğ¢ ĞĞ¢ API:")
            print(f"   HTTP Status Code: {response.status_code}")
            print(f"   Response Headers: {dict(response.headers)}")
            
            if response.status_code != 200:
                error_details = response.text if hasattr(response, 'text') else str(response.status_code)
                try:
                    error_json = response.json()
                    print(f"   ğŸ“‹ JSON Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸: {error_json}")
                except:
                    print(f"   ğŸ“‹ Ğ¢ĞµĞºÑÑ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸: {error_details}")
                
                print(f"\nâŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ HTTP {response.status_code}")
                print(f"   Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸: {error_details}")
                print(f"   URL: {self.llm_client.base_url}")
                print(f"   ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ² payload: {payload.get('model', 'N/A')}")
                print(f"   Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ API: {api_format}")
                print(f"\nğŸ’¡ Ğ’ĞĞ—ĞœĞĞ–ĞĞ«Ğ• ĞŸĞ Ğ˜Ğ§Ğ˜ĞĞ«:")
                print(f"   1. ĞĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ¼Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ¾ Ğ±Ñ‹Ñ‚ÑŒ Ñ Ğ´ĞµÑ„Ğ¸ÑĞ°Ğ¼Ğ¸: claude-3-5-sonnet)")
                print(f"   2. ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ ProxyAPI")
                print(f"   3. ĞĞµĞ²ĞµÑ€Ğ½Ñ‹Ğ¹ API ĞºĞ»ÑÑ‡ Ğ¸Ğ»Ğ¸ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ ÑÑ€ĞµĞ´ÑÑ‚Ğ²")
                print(f"   4. ĞĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°")
                return self._get_fallback_analysis(
                    news.get('hotness', 0),
                    news.get('urls', []),
                    news.get('published_at', ''),
                    news.get('source', 'Unknown source')
                )
            
            print(f"âœ… Ğ£ÑĞ¿ĞµÑˆĞ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ API")
            try:
                result = response.json()
            except json.JSONDecodeError as e:
                print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞ¸Ñ‚ÑŒ JSON Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ API")
                print(f"   ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
                print(f"   Ğ¢ĞµĞºÑÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 500 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²): {response.text[:500] if hasattr(response, 'text') else 'N/A'}")
                return self._get_fallback_analysis(
                    news.get('hotness', 0),
                    news.get('urls', []),
                    news.get('published_at', ''),
                    news.get('source', 'Unknown source')
                )
            
            print(f"ğŸ“‹ ĞšĞ»ÑÑ‡Ğ¸ Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ: {list(result.keys()) if isinstance(result, dict) else 'not a dict'}")
            
            # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° API
            if api_format == "anthropic":
                # Anthropic: result['content'][0]['text']
                print(f"ğŸ” ĞŸĞ¾Ğ¸ÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Anthropic...")
                if 'content' not in result:
                    print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: Anthropic API response missing 'content' field")
                    print(f"   Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ ĞºĞ»ÑÑ‡Ğ¸: {list(result.keys())}")
                    print(f"   ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚: {str(result)[:500]}")
                    return self._get_fallback_analysis(
                        news.get('hotness', 0),
                        news.get('urls', []),
                        news.get('published_at', ''),
                        news.get('source', 'Unknown source')
                    )
                
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ content - ÑÑ‚Ğ¾ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸ Ğ½Ğµ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹
                if not isinstance(result['content'], list) or len(result['content']) == 0:
                    print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: Anthropic API response 'content' is not a list or is empty")
                    print(f"   Ğ¢Ğ¸Ğ¿ content: {type(result['content'])}")
                    print(f"   Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ content: {result['content']}")
                    print(f"   ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚: {str(result)[:500]}")
                    return self._get_fallback_analysis(
                        news.get('hotness', 0),
                        news.get('urls', []),
                        news.get('published_at', ''),
                        news.get('source', 'Unknown source')
                    )
                
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚ - ÑÑ‚Ğ¾ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ
                first_content = result['content'][0]
                if not isinstance(first_content, dict):
                    print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: Anthropic API response 'content[0]' is not a dict")
                    print(f"   Ğ¢Ğ¸Ğ¿ content[0]: {type(first_content)}")
                    print(f"   Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ content[0]: {first_content}")
                    print(f"   ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚: {str(result)[:500]}")
                    return self._get_fallback_analysis(
                        news.get('hotness', 0),
                        news.get('urls', []),
                        news.get('published_at', ''),
                        news.get('source', 'Unknown source')
                    )
                
                # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚
                content = first_content.get('text', '')
                if not content:
                    # Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾, Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ² Ğ´Ñ€ÑƒĞ³Ğ¾Ğ¼ Ğ¿Ğ¾Ğ»Ğµ
                    print(f"âš ï¸ ĞŸĞ¾Ğ»Ğµ 'text' Ğ¿ÑƒÑÑ‚Ğ¾Ğµ, Ğ¸Ñ‰ĞµĞ¼ Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ»Ñ...")
                    print(f"   ĞšĞ»ÑÑ‡Ğ¸ Ğ² content[0]: {list(first_content.keys())}")
                    # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ñ‚ĞµĞºÑÑ‚ Ğ² Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ÑÑ…
                    for key in ['content', 'message', 'text']:
                        if key in first_content:
                            potential_text = first_content[key]
                            if isinstance(potential_text, str) and potential_text.strip():
                                content = potential_text
                                print(f"   âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½ Ñ‚ĞµĞºÑÑ‚ Ğ² Ğ¿Ğ¾Ğ»Ğµ '{key}'")
                                break
                
                if not content:
                    print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Anthropic API")
                    print(f"   Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° content[0]: {first_content}")
                    print(f"   ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚: {str(result)[:500]}")
                    return self._get_fallback_analysis(
                        news.get('hotness', 0),
                        news.get('urls', []),
                        news.get('published_at', ''),
                        news.get('source', 'Unknown source')
                    )
                
                print(f"âœ… ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½ Ğ¸Ğ· result['content'][0]['text']")
                print(f"   Ğ”Ğ»Ğ¸Ğ½Ğ° ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°: {len(content)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
            else:
                # OpenAI Ğ¸ OpenRouter: result['choices'][0]['message']['content']
                print(f"ğŸ” ĞŸĞ¾Ğ¸ÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ OpenAI/OpenRouter...")
                if 'choices' not in result:
                    print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: API response missing 'choices' field")
                    print(f"   Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ ĞºĞ»ÑÑ‡Ğ¸: {list(result.keys())}")
                    print(f"   ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚: {str(result)[:500]}")
                    return self._get_fallback_analysis(
                        news.get('hotness', 0),
                        news.get('urls', []),
                        news.get('published_at', ''),
                        news.get('source', 'Unknown source')
                    )
                
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ choices - ÑÑ‚Ğ¾ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸ Ğ½Ğµ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹
                if not isinstance(result['choices'], list) or len(result['choices']) == 0:
                    print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: API response 'choices' is not a list or is empty")
                    print(f"   Ğ¢Ğ¸Ğ¿ choices: {type(result['choices'])}")
                    print(f"   Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ choices: {result['choices']}")
                    print(f"   ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚: {str(result)[:500]}")
                    return self._get_fallback_analysis(
                        news.get('hotness', 0),
                        news.get('urls', []),
                        news.get('published_at', ''),
                        news.get('source', 'Unknown source')
                    )
                
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ choice
                first_choice = result['choices'][0]
                if not isinstance(first_choice, dict):
                    print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: API response 'choices[0]' is not a dict")
                    print(f"   Ğ¢Ğ¸Ğ¿ choices[0]: {type(first_choice)}")
                    print(f"   Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ choices[0]: {first_choice}")
                    return self._get_fallback_analysis(
                        news.get('hotness', 0),
                        news.get('urls', []),
                        news.get('published_at', ''),
                        news.get('source', 'Unknown source')
                    )
                
                # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ message
                message = first_choice.get('message', {})
                if not isinstance(message, dict):
                    print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: API response 'choices[0].message' is not a dict")
                    print(f"   Ğ¢Ğ¸Ğ¿ message: {type(message)}")
                    print(f"   Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ message: {message}")
                    return self._get_fallback_analysis(
                        news.get('hotness', 0),
                        news.get('urls', []),
                        news.get('published_at', ''),
                        news.get('source', 'Unknown source')
                    )
                
                content = message.get('content', '')
                if not content:
                    print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° API")
                    print(f"   Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° choices[0]: {first_choice}")
                    print(f"   ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚: {str(result)[:500]}")
                    return self._get_fallback_analysis(
                        news.get('hotness', 0),
                        news.get('urls', []),
                        news.get('published_at', ''),
                        news.get('source', 'Unknown source')
                    )
                
                print(f"âœ… ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½ Ğ¸Ğ· result['choices'][0]['message']['content']")
                print(f"   Ğ”Ğ»Ğ¸Ğ½Ğ° ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°: {len(content)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ½Ğµ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹
            if not content or not content.strip():
                print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ LLM")
                print(f"   Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: {list(result.keys()) if isinstance(result, dict) else 'not a dict'}")
                print(f"   ĞŸĞµÑ€Ğ²Ñ‹Ğµ 200 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: {str(result)[:200]}")
                return self._get_fallback_analysis(
                    news.get('hotness', 0),
                    news.get('urls', []),
                    news.get('published_at', ''),
                    news.get('source', 'Unknown source')
                )

            # Normalize model response: remove markdown fences and extract JSON
            print(f"\nğŸ”§ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° LLM...")
            import re
            raw_content = content or ""
            print(f"   Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 200 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²): {raw_content[:200]}")
            
            if "```json" in raw_content:
                print(f"   ĞĞ°Ğ¹Ğ´ĞµĞ½ Ğ±Ğ»Ğ¾Ğº ```json")
                try:
                    content = raw_content.split("```json", 1)[1].split("```", 1)[0]
                    print(f"   Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½ JSON Ğ¸Ğ· Ğ±Ğ»Ğ¾ĞºĞ°")
                except Exception as e:
                    print(f"   âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ· ```json: {e}")
                    content = raw_content
            elif "```" in raw_content:
                print(f"   ĞĞ°Ğ¹Ğ´ĞµĞ½ Ğ±Ğ»Ğ¾Ğº ```")
                try:
                    content = raw_content.split("```", 1)[1].split("```", 1)[0]
                    print(f"   Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ¸Ğ· Ğ±Ğ»Ğ¾ĞºĞ°")
                except Exception as e:
                    print(f"   âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ· ```: {e}")
                    content = raw_content
            else:
                print(f"   Markdown Ğ±Ğ»Ğ¾ĞºĞ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ²ĞµÑÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚")
                content = raw_content

            # Extract JSON substring by outer curly braces
            print(f"   ĞŸĞ¾Ğ¸ÑĞº JSON Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°...")
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
            if json_match:
                content = json_match.group(0)
                print(f"   âœ… JSON Ğ¾Ğ±ÑŠĞµĞºÑ‚ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½")
            else:
                print(f"   âš ï¸ JSON Ğ¾Ğ±ÑŠĞµĞºÑ‚ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ½Ñ‹Ğ¼ Ğ²Ñ‹Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ĞµĞ¼")

            # Remove problematic control characters, keeping line breaks
            def _sanitize(s: str) -> str:
                if not isinstance(s, str):
                    return s
                # Remove BOM and null bytes/vertical tabs/form feeds
                s = s.replace('\ufeff', '')
                s = s.replace('\x00', '').replace('\x0b', ' ').replace('\x0c', ' ')
                return s

            content = _sanitize(content)
            print(f"   ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸ (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 300 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²): {content[:300]}")

            # Check that valid content remains after all processing
            if not content or not content.strip():
                print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸")
                return self._get_fallback_analysis(
                    news.get('hotness', 0),
                    news.get('urls', []),
                    news.get('published_at', ''),
                    news.get('source', 'Unknown source')
                )

            # Parse JSON, allowing unescaped control characters inside strings
            print(f"\nğŸ“Š ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ JSON...")
            try:
                analysis = json.loads(content.strip(), strict=False)
                print(f"âœ… JSON ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞµĞ½")
                print(f"   ĞšĞ»ÑÑ‡Ğ¸ Ğ² Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ: {list(analysis.keys()) if isinstance(analysis, dict) else 'not a dict'}")
                print(f"   ĞĞ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ analysis_text: {'analysis_text' in analysis if isinstance(analysis, dict) else False}")
                print("="*60)
                print("âœ… Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ ĞĞĞĞ›Ğ˜Ğ—Ğ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞ")
                print("="*60 + "\n")
                return analysis
            except json.JSONDecodeError as e:
                print(f"âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° JSON: {e}")
                print(f"   ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 500 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²): {content[:500]}")
                raise
            
        except json.JSONDecodeError as e:
            print(f"\nâŒ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ ĞĞ¨Ğ˜Ğ‘ĞšĞ: Ğ½ĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON")
            print(f"   ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            print(f"   ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 500 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²): {content[:500] if 'content' in locals() else 'N/A'}")
            import traceback
            traceback.print_exc()
            print("="*60)
            print("âŒ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ ĞĞĞĞ›Ğ˜Ğ—Ğ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ Ğ¡ ĞĞ¨Ğ˜Ğ‘ĞšĞĞ™")
            print("="*60 + "\n")
            return self._get_fallback_analysis(
                news.get('hotness', 0),
                news.get('urls', []),
                news.get('published_at', ''),
                news.get('source', 'Unknown source')
            )
        except KeyError as e:
            print(f"\nâŒ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ ĞĞ¨Ğ˜Ğ‘ĞšĞ: Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ ĞºĞ»ÑÑ‡ Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ")
            print(f"   ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹ ĞºĞ»ÑÑ‡: {e}")
            print(f"   Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: {list(result.keys()) if 'result' in locals() and isinstance(result, dict) else 'N/A'}")
            import traceback
            traceback.print_exc()
            print("="*60)
            print("âŒ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ ĞĞĞĞ›Ğ˜Ğ—Ğ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ Ğ¡ ĞĞ¨Ğ˜Ğ‘ĞšĞĞ™")
            print("="*60 + "\n")
            return self._get_fallback_analysis(
                news.get('hotness', 0),
                news.get('urls', []),
                news.get('published_at', ''),
                news.get('source', 'Unknown source')
            )
        except Exception as e:
            print(f"\nâŒ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ ĞĞ¨Ğ˜Ğ‘ĞšĞ: Ğ½ĞµĞ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°")
            print(f"   Ğ¢Ğ¸Ğ¿ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸: {type(e).__name__}")
            print(f"   Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ: {e}")
            import traceback
            traceback.print_exc()
            print("="*60)
            print("âŒ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ ĞĞĞĞ›Ğ˜Ğ—Ğ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ Ğ¡ ĞĞ¨Ğ˜Ğ‘ĞšĞĞ™")
            print("="*60 + "\n")
            return self._get_fallback_analysis(
                news.get('hotness', 0),
                news.get('urls', []),
                news.get('published_at', ''),
                news.get('source', 'Unknown source')
            )
    
    def _create_analysis_card_prompt(self, headline: str, content: str, tickers: list, hotness: float, urls: list, published_at: str, source: str) -> str:
        """Prompt for generating news analytical card"""
        tickers_str = ', '.join(tickers) if tickers else 'â€”'
        url_str = urls[0] if urls else 'no link'
        
        # Always use English for user-facing content
        lang_instruction = "in English"
        
        return f"""You are a financial news analytics agent for the AI ALPHA PULSE Telegram bot. Your task is to create a compact, explainable analytical card {lang_instruction}.

IMPORTANT: The news article may be in any language (Russian, English, etc.), but your analysis MUST be written entirely in English. Translate and analyze the content, then present your analysis in English.

INPUT DATA:
Headline: {headline}
Text: {content[:2000]}
Tickers: {tickers_str}
Source: {source}
Publication time: {published_at}
URL: {url_str}
Hotness score: {hotness:.2f}

OUTPUT REQUIREMENTS:
Create an analytical card in Markdown format (Telegram-compatible). Card language: {lang_instruction}. IMPORTANT: All text must be in English, regardless of the source news language.

MANDATORY FIELDS (strictly in this order):

1. TL;DR (20-30 words): News essence and its impact on markets/assets
2. Key facts (2-4 points): Specific facts from text, no speculation
3. Affected assets: Comma-separated ticker list or "â€”"
4. Sentiment score: Number from -1 to 1 and brief explanation (why positive/negative/neutral)
5. News score: Number from 0 to 1 and main drivers (sentiment / mentions / authority)
6. Recommendation: "Monitor" / "Bullish (consider buy)" / "Bearish (consider sell)" / "No action" + 1-2 sentence explanation
7. Confidence: "Low" / "Medium" / "High" + justification (why this confidence level)

STYLE:
- Brief, neutral, business-like. Maximum 700 characters
- Use phrases: "consider", "monitor", "may indicate" (don't give direct financial advice)
- If data is insufficient â€” indicate this in Confidence and TL;DR
- Don't make up statistics if they're not in the text
- Use emojis where appropriate

Reply ONLY in JSON format:
{{
    "analysis_text": "ğŸ” *TL;DR:* ...\\n\\nğŸ“Œ *Key facts:*\\nâ€¢ Fact 1\\nâ€¢ Fact 2\\nâ€¢ Fact 3\\n\\nğŸ“ˆ *Affected assets:* ...\\nğŸ’¡ *Sentiment:* ... â€” ...\\nâ­ *News score:* ... â€” drivers: ...\\n\\nğŸ§­ *Recommendation:* ... â€” ...\\nğŸ”’ *Confidence:* ... â€” ...\\n\\nğŸ”— {url_str}"
}}

IMPORTANT: All card text must be in one line analysis_text with escaped line breaks (\\n). Use Markdown formatting (*bold text*) for field headers."""
    
    def _get_fallback_analysis(self, hotness: float, urls: list, published_at: str, source: str) -> Dict:
        """Fallback analysis on LLM error"""
        url_str = urls[0] if urls else 'no link'
        
        fallback_text = f"""ğŸ” *TL;DR:* Analysis temporarily unavailable â€” LLM processing error.

ğŸ“Œ *Key facts:*
â€¢ News requires manual analysis
â€¢ Automatic processing failed

ğŸ“ˆ *Affected assets:* â€”
ğŸ’¡ *Sentiment:* 0.0 â€” not determined
â­ *News score:* {hotness:.2f} â€” baseline hotness score

ğŸ§­ *Recommendation:* Monitor â€” additional analysis required
ğŸ”’ *Confidence:* Low â€” automatic analysis unavailable

ğŸ”— {url_str}"""
        
        return {
            'analysis_text': fallback_text
        }

