#!/usr/bin/env python3
"""
–í–æ—Ä–∫–µ—Ä –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π:
–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ‚Üí –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è ‚Üí LLM –∞–Ω–∞–ª–∏–∑

–ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –≤ Docker-–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫—Ä—É–≥–ª–æ—Å—É—Ç–æ—á–Ω–æ
"""
import os
import sys
import time
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.append(str(Path(__file__).parent))

from src.database import get_db_connection
from src.normalization.process_articles import ArticleProcessor
from src.dedup.logic import process_new_batch
from src.dedup.schema import init as init_dedup
from src.llm.processor import LLMNewsProcessor


class PipelineWorker:
    """–í–æ—Ä–∫–µ—Ä –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    
    def __init__(self):
        self.check_interval = int(os.getenv('PIPELINE_CHECK_INTERVAL', '300'))  # 5 –º–∏–Ω—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.batch_size = int(os.getenv('PIPELINE_BATCH_SIZE', '100'))
        self.llm_limit = int(os.getenv('PIPELINE_LLM_LIMIT', '50'))
        self.llm_delay = float(os.getenv('LLM_DELAY', '1.0'))
        self.llm_model = os.getenv('LLM_MODEL', 'deepseek/deepseek-chat')
        
        self.normalizer = ArticleProcessor()
        self.db_conn = get_db_connection()
        
        print("="*60)
        print("üöÄ PIPELINE WORKER")
        print("="*60)
        print(f"üìä –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏: {self.check_interval}—Å")
        print(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.batch_size}")
        print(f"ü§ñ LLM –ª–∏–º–∏—Ç: {self.llm_limit}")
        print(f"‚è±Ô∏è  LLM –∑–∞–¥–µ—Ä–∂–∫–∞: {self.llm_delay}—Å")
        print(f"üéØ LLM –º–æ–¥–µ–ª—å: {self.llm_model}")
        print("="*60)
    
    def run_normalization(self) -> int:
        """–ó–∞–ø—É—Å–∫ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π"""
        print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] üìù –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è...")
        
        try:
            self.normalizer.connect_db()
            status = self.normalizer.get_processing_status()
            
            if status['is_up_to_date']:
                print("   ‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏")
                return 0
            
            print(f"   üìä –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {status['unprocessed_count']}")
            articles = self.normalizer.load_unprocessed_articles(limit=self.batch_size)
            
            if not articles:
                print("   ‚úÖ –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                return 0
            
            stats = self.normalizer.process_articles_batch(articles, self.batch_size)
            print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed_articles']}, –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ: {stats['filtered_articles']}")
            
            return stats['processed_articles']
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return 0
        finally:
            self.normalizer.close_db()
    
    def run_deduplication(self) -> int:
        """–ó–∞–ø—É—Å–∫ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
        print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] üîç –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
        
        try:
            self.db_conn.connect()
            init_dedup(self.db_conn._connection)
            
            n = process_new_batch(self.db_conn._connection, k_neighbors=30)
            print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {n}")
            
            return n
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {e}")
            return 0
        finally:
            self.db_conn.close()
    
    def run_llm_analysis(self) -> int:
        """–ó–∞–ø—É—Å–∫ LLM –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ü§ñ LLM –∞–Ω–∞–ª–∏–∑...")
        
        try:
            self.db_conn.connect()
            
            processor = LLMNewsProcessor(
                conn=self.db_conn._connection,
                model=self.llm_model
            )
            
            stats = processor.process_batch(
                limit=self.llm_limit,
                delay=self.llm_delay
            )
            
            print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed']}, –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}, –û—à–∏–±–æ–∫: {stats['errors']}")
            
            return stats['processed']
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ LLM –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return 0
        finally:
            self.db_conn.close()
    
    def run_cycle(self):
        """–û–¥–∏–Ω —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        print(f"\n{'='*60}")
        print(f"üîÑ –ù–ê–ß–ê–õ–û –¶–ò–ö–õ–ê: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")
        
        total_start = time.time()
        
        # –®–∞–≥ 1: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        normalized_count = self.run_normalization()
        
        # –®–∞–≥ 2: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è (–µ—Å–ª–∏ –±—ã–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –Ω–æ–≤—ã–µ —Å—Ç–∞—Ç—å–∏)
        dedup_count = 0
        if normalized_count > 0:
            dedup_count = self.run_deduplication()
        else:
            print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (–Ω–µ—Ç –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π)")
        
        # –®–∞–≥ 3: LLM –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –±—ã–ª–∏ —Å–æ–∑–¥–∞–Ω—ã –Ω–æ–≤—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã)
        llm_count = 0
        if dedup_count > 0 or normalized_count > 0:
            llm_count = self.run_llm_analysis()
        else:
            print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ LLM –∞–Ω–∞–ª–∏–∑–∞ (–Ω–µ—Ç –Ω–æ–≤—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤)")
        
        total_time = time.time() - total_start
        
        print(f"\n{'='*60}")
        print(f"‚úÖ –¶–ò–ö–õ –ó–ê–í–ï–†–®–ï–ù: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {total_time:.1f}—Å")
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   ‚Ä¢ –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: {normalized_count}")
        print(f"   ‚Ä¢ –î–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {dedup_count}")
        print(f"   ‚Ä¢ LLM –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {llm_count}")
        print(f"{'='*60}")
    
    def run(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –≤–æ—Ä–∫–µ—Ä–∞"""
        print(f"\nüöÄ –í–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω –≤ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"‚è∞ –°–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ {self.check_interval}—Å\n")
        
        cycle_count = 0
        
        while True:
            try:
                cycle_count += 1
                print(f"\n{'#'*60}")
                print(f"# –¶–ò–ö–õ #{cycle_count}")
                print(f"{'#'*60}")
                
                self.run_cycle()
                
                print(f"\nüí§ –û–∂–∏–¥–∞–Ω–∏–µ {self.check_interval}—Å –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏...")
                time.sleep(self.check_interval)
                
            except KeyboardInterrupt:
                print("\n\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞ –ø–æ Ctrl+C...")
                break
            except Exception as e:
                print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ: {e}")
                import traceback
                traceback.print_exc()
                print(f"\nüí§ –û–∂–∏–¥–∞–Ω–∏–µ {self.check_interval}—Å –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º...")
                time.sleep(self.check_interval)


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    try:
        worker = PipelineWorker()
        worker.run()
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

